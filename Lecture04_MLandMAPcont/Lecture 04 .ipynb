{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood and MAP continued...\n",
    "\n",
    "## MLE of Mean of Gaussian\n",
    "\n",
    "*  Let $\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_N$ be samples from a multi-variance Normal distribution with known covariance matrix and an unknown mean.  Given this data, obtain the ML estimate of the mean vector. \n",
    "\t\\begin{equation}\n",
    "\tp(\\mathbf{x}_k| {{\\mu}}) = \\frac{1}{(2\\pi)^{\\frac{l}{2}}\\left| \\Sigma \\right|^{\\frac{1}{2}}}\\exp\\left( -\\frac{1}{2}(\\mathbf{x}_k - {{\\mu}})^T\\Sigma^{-1}(\\mathbf{x}_k - {\\mu})\\right)\n",
    "\t\\end{equation}\n",
    "* We can define our likelihood given the $N$ data points.  We are assuming these data points are drawn independently but from an identical distribution (i.i.d.):\n",
    "\t\\begin{equation}\n",
    "\t\\prod_{n=1}^N p(\\mathbf{x}_n| {{\\mu}}) = \\prod_{n=1}^N \\frac{1}{(2\\pi)^{\\frac{l}{2}}\\left| \\Sigma \\right|^{\\frac{1}{2}}}\\exp\\left( -\\frac{1}{2}(\\mathbf{x}_n - {{\\mu}})^T\\Sigma^{-1}(\\mathbf{x}_n - {\\mu})\\right)\n",
    "\t\\end{equation}\n",
    "*  We can apply our \"trick\" to simplify\n",
    "\t\\begin{eqnarray}\n",
    "\t\\mathscr{L} &=& \\ln \\prod_{n=1}^N p(\\mathbf{x}_n| {{\\mu}}) = \\ln \\prod_{n=1}^N \\frac{1}{(2\\pi)^{\\frac{l}{2}}\\left| \\Sigma \\right|^{\\frac{1}{2}}}\\exp\\left( -\\frac{1}{2}(\\mathbf{x}_n - {{\\mu}})^T\\Sigma^{-1}(\\mathbf{x}_n - {\\mu})\\right)\\\\\n",
    "\t&=& \\sum_{n=1}^N  \\ln \\frac{1}{(2\\pi)^{\\frac{l}{2}}\\left| \\Sigma \\right|^{\\frac{1}{2}}}\\exp\\left( -\\frac{1}{2}(\\mathbf{x}_n - {{\\mu}})^T\\Sigma^{-1}(\\mathbf{x}_n - {\\mu})\\right)\\\\\n",
    "\t&=& \\sum_{n=1}^N  \\left( \\ln \\frac{1}{(2\\pi)^{\\frac{l}{2}}\\left| \\Sigma \\right|^{\\frac{1}{2}}} + \\left( -\\frac{1}{2}(\\mathbf{x}_n - {{\\mu}})^T\\Sigma^{-1}(\\mathbf{x}_n - {\\mu})\\right) \\right) \\\\\n",
    "\t&=&  - N \\ln (2\\pi)^{\\frac{l}{2}}\\left| \\Sigma \\right|^{\\frac{1}{2}} + \\sum_{n=1}^N  \\left( -\\frac{1}{2}(\\mathbf{x}_n - {{\\mu}})^T\\Sigma^{-1}(\\mathbf{x}_n - {\\mu}) \\right) \n",
    "\t\\end{eqnarray}\n",
    "* Now, lets maximize:\n",
    "\t\\begin{eqnarray}\n",
    "\t\\frac{\\partial \\mathscr{L}}{\\partial \\mu} &=& \\frac{\\partial}{\\partial \\mu} \\left[- N \\ln (2\\pi)^{\\frac{l}{2}}\\left| \\Sigma \\right|^{\\frac{1}{2}} + \\sum_{n=1}^N  \\left( -\\frac{1}{2}(\\mathbf{x}_n - {{\\mu}})^T\\Sigma^{-1}(\\mathbf{x}_n - {\\mu}) \\right)\\right] = 0 \\\\\n",
    "\t&\\rightarrow& \\sum_{n=1}^N  \\Sigma^{-1}(\\mathbf{x}_n - {\\mu}) = 0\\\\\n",
    "\t&\\rightarrow& \\sum_{n=1}^N  \\Sigma^{-1}\\mathbf{x}_n  = \\sum_{n=1}^N  \\Sigma^{-1} {\\mu}\\\\\n",
    "\t&\\rightarrow& \\Sigma^{-1} \\sum_{n=1}^N \\mathbf{x}_n  = \\Sigma^{-1} {\\mu} N\\\\\n",
    "\t&\\rightarrow& \\sum_{n=1}^N \\mathbf{x}_n  = {\\mu} N\\\\\n",
    "\t&\\rightarrow& \\frac{\\sum_{n=1}^N \\mathbf{x}_n}{N} = {\\mu}\\\\\n",
    "\t\\end{eqnarray}\n",
    "* So, the ML estimate of $\\mu$ is the sample mean!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP of Mean of Gaussian\n",
    "\n",
    "* To get a MAP estimate of the mean of a Gaussian, we apply a prior distribution and maximize the posterior. \n",
    "* Lets use a Gaussian prior on the mean (because it has a *conjugate prior* relationship)\n",
    "\n",
    "\\begin{eqnarray}\n",
    "p(\\mu|X, \\mu_0, \\sigma_0^2, \\sigma^2) &\\propto& \\mathscr{N}(X|\\mu, \\sigma^2)\\mathscr{N}(\\mu|\\mu_0, \\sigma_0^2)\\\\\n",
    "&=& \\prod_{n=1}^N \\left(\\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(x_n-\\mu\\right)^2 \\right\\}\\right)\\frac{1}{\\sqrt{2\\pi \\sigma_0^2}} \\exp\\left\\{-\\frac{1}{2\\sigma_0^2}\\left(\\mu-\\mu_0\\right)^2 \\right\\}\\nonumber\\\\\n",
    "\\mathscr{L} &=& -\\frac{N}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{n=1}^N(x_n-\\mu)^2 - \\frac{N}{2}\\ln(2\\pi \\sigma_0^2) - \\frac{N}{2\\sigma_0^2}(\\mu - \\mu_0)^2\\\\\n",
    "\\frac{\\partial \\mathscr{L}}{\\partial \\mu} &=&  - \\frac{N}{\\sigma^2}\\mu - \\frac{N}{\\sigma_0^2}\\mu + \\frac{N}{\\sigma_0^2}\\mu_0 + \\frac{1}{\\sigma^2}\\sum_{n=1}^N x_n = 0\\\\\n",
    "N\\mu\\left(\\frac{N\\sigma_0^2 + \\sigma^2}{\\sigma^2\\sigma_0^2} \\right) &=& \\frac{1}{\\sigma^2}\\sum_{n=1}^N x_n + \\frac{1}{\\sigma_0^2}\\mu_0 \\\\\n",
    "\\mu_{MAP} &=& \\frac{\\sigma_0^2}{N\\sigma_0^2 + N\\sigma^2}\\sum_{n=1}^N x_n + \\frac{\\mu_0\\sigma^2}{N\\sigma_0^2 + N\\sigma^2}\n",
    "\\end{eqnarray}\n",
    "\n",
    "* *Does this result make sense?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
